{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot as plt\n",
    "from  sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import  make_pipeline,Pipeline\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\hp\\Desktop\\house_sale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "def data_preprocessor(X,y):\n",
    "        \"\"\"Function to Prepocess the data \"\"\"\n",
    "        numeric_transformer = Pipeline(\n",
    "                steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "            )\n",
    "\n",
    "        categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"numeric\", numeric_transformer, X.select_dtypes(np.number).columns.tolist()),\n",
    "                    (\"category\", categorical_transformer,X.select_dtypes(\"object\").columns.tolist()),\n",
    "                ]\n",
    "            )\n",
    "        return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_evaluator_regressor(model,xtest,ytest):\n",
    "         ypred_model=model.predict(xtest)\n",
    "         r2score=r2_score(ytest,ypred_model)\n",
    "         mse=mean_absolute_error(ytest,ypred_model)\n",
    "         return r2score,mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_Regressor(X,y,start,end,parms):\n",
    "\n",
    "        Listing=[]\n",
    "\n",
    "        preprocessor=data_preprocessor(X,y)\n",
    "        # st.write(\"In main FUnction \")\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=45)\n",
    "        for i in range(start,end):\n",
    "        # ****************Feature Seclortot**********************************************\n",
    "                feature_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i))])\n",
    "                feature_selector.fit(xtrain,ytrain)\n",
    "        # ****************Model Seclortot**********************************************\n",
    "                model_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i)),\n",
    "                    (\"classifier\",  KNeighborsRegressor())]\n",
    "                )\n",
    "                model_selector.fit(xtrain,ytrain)\n",
    "        # *********************************Hyper Parametet***********************************\n",
    "                grid=GridSearchCV(model_selector,parms,cv=4,n_jobs=-1,verbose=3)\n",
    "                grid.fit(xtrain,ytrain)\n",
    "                feature=grid.best_params_\n",
    "                model=grid.best_estimator_\n",
    "\n",
    "                # st.markdown(\"_\"*200)\n",
    "                result_parameter,mae_parameter=result_evaluator_regressor(model,xtest,ytest)\n",
    "\n",
    "                print(f\"R2 score with best parameter{result_parameter}\")\n",
    "                print(f\"Mean Absoulte Error with best parameter{mae_parameter}\")\n",
    "                \n",
    "        #****************************Result Generation ******************************\n",
    "                result,mae=result_evaluator_regressor(model_selector,xtest,ytest)\n",
    "           \n",
    "\n",
    "                print(f\"Accuracy without  Best parameter{result}\")\n",
    "                print(f\"Mean Absoulte Error without  best parameter{mae}\")\n",
    "              \n",
    "        #*********************************Working on features****************************\n",
    "                xopt=feature_selector.get_feature_names_out()\n",
    "                feature_selection=[]\n",
    "                for x in xopt:\n",
    "                    feature_selection.append(x.split(\"__\")[1])\n",
    "                # st.write(feature_selection)\n",
    "                print(\"The feature Selection are as follow-:\")\n",
    "                print(feature_selection)\n",
    "                print(feature)\n",
    "                print(feature_selection)\n",
    "                Listing.append({\n",
    "                    \"i\":i,\n",
    "                    \"result\":result,\n",
    "                    \"mae\":mae,\n",
    "                    \"result_parameter\":result_parameter,\n",
    "                    \"mae_parameter\":mae_parameter,\n",
    "                #     \"Error_model\":result_model,\n",
    "                    \"columns\":feature_selection,\n",
    "                    \"parameter\":feature\n",
    "                })\n",
    "        print(Listing)\n",
    "\n",
    "        return Listing,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"SalePrice\"])\n",
    "y=df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parms={}\n",
    "# listing,model=knn_Regressor(X,y,1,10,parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.1\n",
      "1.2\n",
      "1.3\n",
      "1.4\n",
      "1.5\n",
      "1.6\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1,0.6,0.1):\n",
    "#     print(i)\n",
    "import numpy as np\n",
    "for i in  np.arange(1,1.6,0.1):\n",
    "    print(round(i,1))\n",
    "    # print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_boosting(X,y,start,end,parms2):\n",
    "\n",
    "        Listing=[]\n",
    "\n",
    "        preprocessor=data_preprocessor(X,y)\n",
    "        # st.write(\"In main FUnction \")\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=45)\n",
    "    #     parms={\n",
    "    #     \"classifier__splitter\":[\"random\", \"best\"],\n",
    "    #     \"classifier__max_features\":[\"sqrt\", \"log2\", None],\n",
    "    #     'classifier__max_depth':[10,15,20,25,30],\n",
    "    # }   \n",
    "        for i in range(start,end):\n",
    "        # ****************Feature Seclortot**********************************************\n",
    "                feature_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i))])\n",
    "                feature_selector.fit(xtrain,ytrain)\n",
    "        # ****************Model Seclortot**********************************************\n",
    "                model_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i)),\n",
    "                    (\"classifier\", GradientBoostingRegressor())]\n",
    "                )\n",
    "                model_selector.fit(xtrain,ytrain)\n",
    "        # *********************************Hyper Parametet***********************************\n",
    "                grid=GridSearchCV(model_selector,parms2,cv=4,n_jobs=-1,verbose=3)\n",
    "                grid.fit(xtrain,ytrain)\n",
    "                feature=grid.best_params_\n",
    "                model=grid.best_estimator_\n",
    "\n",
    "                # st.markdown(\"_\"*200)\n",
    "                result_parameter,mae_parameter=result_evaluator_regressor(model,xtest,ytest)\n",
    "                # ypred_model=model.predict(xtest)\n",
    "                # result_model=r2_score(ytest,ypred_model)\n",
    "                # st.markdown(\"_\"*200)\n",
    "                print(f\"R2 score with best parameter{result_parameter}\")\n",
    "                print(f\"Mean Absoulte Error with best parameter{mae_parameter}\")\n",
    "                # ypred_model=model.predict(xtest)\n",
    "                # result_model=r2_score(ytest,ypred_model)\n",
    "                # st.write(f\"Accuracy with best parameter{result_parameter}\")\n",
    "                # print(f\"R2score of Result Modelwith best estimator is : {result_model}\")\n",
    "        #****************************Result Generation ******************************\n",
    "                result,mae=result_evaluator_regressor(model_selector,xtest,ytest)\n",
    "                # ypred=model_selector.predict(xtest)\n",
    "                # result=r2_score(ytest,ypred)\n",
    "\n",
    "                print(f\"Accuracy without  Best parameter{result}\")\n",
    "                print(f\"Mean Absoulte Error without  best parameter{mae}\")\n",
    "                # print(f\"R2score is without estimator {result}\")\n",
    "                # print(confusion_matrix(ypred,ytest))\n",
    "                # print(classification_report(ypred,ytest))\n",
    "        #*********************************Working on features****************************\n",
    "                xopt=feature_selector.get_feature_names_out()\n",
    "                feature_selection=[]\n",
    "                for x in xopt:\n",
    "                    feature_selection.append(x.split(\"__\")[1])\n",
    "                # st.write(feature_selection)\n",
    "                print(\"The feature Selection are as follow-:\")\n",
    "                print(feature_selection)\n",
    "                print(feature)\n",
    "                print(feature_selection)\n",
    "                Listing.append({\n",
    "                    \"i\":i,\n",
    "                    \"result\":result,\n",
    "                    \"mae\":mae,\n",
    "                    \"result_parameter\":result_parameter,\n",
    "                    \"mae_parameter\":mae_parameter,\n",
    "                #     \"Error_model\":result_model,\n",
    "                    \"columns\":feature_selection,\n",
    "                    \"parameter\":feature\n",
    "                })\n",
    "        print(Listing)\n",
    "\n",
    "        return Listing,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.6829465365496536\n",
      "Mean Absoulte Error with best parameter31867.53777328021\n",
      "Accuracy without  Best parameter0.6829465365496536\n",
      "Mean Absoulte Error without  best parameter31867.53777328021\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual']\n",
      "{}\n",
      "['OverallQual']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.7792029243870768\n",
      "Mean Absoulte Error with best parameter25968.472717934583\n",
      "Accuracy without  Best parameter0.7792082481866902\n",
      "Mean Absoulte Error without  best parameter25967.73224516615\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'GrLivArea']\n",
      "{}\n",
      "['OverallQual', 'GrLivArea']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8291943277950772\n",
      "Mean Absoulte Error with best parameter23580.568350446953\n",
      "Accuracy without  Best parameter0.8291031533309381\n",
      "Mean Absoulte Error without  best parameter23591.95642911034\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'GrLivArea', 'GarageCars']\n",
      "{}\n",
      "['OverallQual', 'GrLivArea', 'GarageCars']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8004824799764145\n",
      "Mean Absoulte Error with best parameter23960.430859393375\n",
      "Accuracy without  Best parameter0.8002386384185913\n",
      "Mean Absoulte Error without  best parameter23992.456534040437\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "{}\n",
      "['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8194177837794026\n",
      "Mean Absoulte Error with best parameter22752.298922035712\n",
      "Accuracy without  Best parameter0.8229618940207315\n",
      "Mean Absoulte Error without  best parameter22745.512756986467\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "{}\n",
      "['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8205714123406088\n",
      "Mean Absoulte Error with best parameter22716.115959733354\n",
      "Accuracy without  Best parameter0.8204322287450654\n",
      "Mean Absoulte Error without  best parameter22699.67136524275\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "{}\n",
      "['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8438852047210122\n",
      "Mean Absoulte Error with best parameter22042.989647109673\n",
      "Accuracy without  Best parameter0.8421407454949636\n",
      "Mean Absoulte Error without  best parameter22099.75905738704\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "{}\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8485472800277731\n",
      "Mean Absoulte Error with best parameter21800.021799983668\n",
      "Accuracy without  Best parameter0.8539613463266922\n",
      "Mean Absoulte Error without  best parameter21624.22111640158\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "{}\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "R2 score with best parameter0.8465296309541718\n",
      "Mean Absoulte Error with best parameter21761.62916943471\n",
      "Accuracy without  Best parameter0.850078106698002\n",
      "Mean Absoulte Error without  best parameter21688.007426350916\n",
      "The feature Selection are as follow-:\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA', 'BsmtQual_Ex']\n",
      "{}\n",
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA', 'BsmtQual_Ex']\n",
      "[{'i': 1, 'result': 0.6829465365496536, 'mae': 31867.53777328021, 'result_parameter': 0.6829465365496536, 'mae_parameter': 31867.53777328021, 'columns': ['OverallQual'], 'parameter': {}}, {'i': 2, 'result': 0.7792082481866902, 'mae': 25967.73224516615, 'result_parameter': 0.7792029243870768, 'mae_parameter': 25968.472717934583, 'columns': ['OverallQual', 'GrLivArea'], 'parameter': {}}, {'i': 3, 'result': 0.8291031533309381, 'mae': 23591.95642911034, 'result_parameter': 0.8291943277950772, 'mae_parameter': 23580.568350446953, 'columns': ['OverallQual', 'GrLivArea', 'GarageCars'], 'parameter': {}}, {'i': 4, 'result': 0.8002386384185913, 'mae': 23992.456534040437, 'result_parameter': 0.8004824799764145, 'mae_parameter': 23960.430859393375, 'columns': ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea'], 'parameter': {}}, {'i': 5, 'result': 0.8229618940207315, 'mae': 22745.512756986467, 'result_parameter': 0.8194177837794026, 'mae_parameter': 22752.298922035712, 'columns': ['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea'], 'parameter': {}}, {'i': 6, 'result': 0.8204322287450654, 'mae': 22699.67136524275, 'result_parameter': 0.8205714123406088, 'mae_parameter': 22716.115959733354, 'columns': ['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA'], 'parameter': {}}, {'i': 7, 'result': 0.8421407454949636, 'mae': 22099.75905738704, 'result_parameter': 0.8438852047210122, 'mae_parameter': 22042.989647109673, 'columns': ['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'GarageCars', 'GarageArea', 'ExterQual_TA'], 'parameter': {}}, {'i': 8, 'result': 0.8539613463266922, 'mae': 21624.22111640158, 'result_parameter': 0.8485472800277731, 'mae_parameter': 21800.021799983668, 'columns': ['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA'], 'parameter': {}}, {'i': 9, 'result': 0.850078106698002, 'mae': 21688.007426350916, 'result_parameter': 0.8465296309541718, 'mae_parameter': 21761.62916943471, 'columns': ['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea', 'ExterQual_TA', 'BsmtQual_Ex'], 'parameter': {}}]\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(columns=[\"SalePrice\"])\n",
    "y=df[\"SalePrice\"]\n",
    "parms={}\n",
    "listing,model=Gradient_boosting(X,y,1,10,parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def Gradient_boosting(X,y,start,end,parms2):\n",
    "\n",
    "        Listing=[]\n",
    "\n",
    "        preprocessor=data_preprocessor(X,y)\n",
    "        # st.write(\"In main FUnction \")\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=45)\n",
    "    #     parms={\n",
    "    #     \"classifier__splitter\":[\"random\", \"best\"],\n",
    "    #     \"classifier__max_features\":[\"sqrt\", \"log2\", None],\n",
    "    #     'classifier__max_depth':[10,15,20,25,30],\n",
    "    # }   \n",
    "        for i in range(start,end):\n",
    "        # ****************Feature Seclortot**********************************************\n",
    "                feature_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i))])\n",
    "                feature_selector.fit(xtrain,ytrain)\n",
    "        # ****************Model Seclortot**********************************************\n",
    "                model_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i)),\n",
    "                    (\"classifier\", DecisionTreeRegressor())]\n",
    "                )\n",
    "                model_selector.fit(xtrain,ytrain)\n",
    "        # *********************************Hyper Parametet***********************************\n",
    "                grid=GridSearchCV(model_selector,parms2,cv=4,n_jobs=-1,verbose=3)\n",
    "                grid.fit(xtrain,ytrain)\n",
    "                feature=grid.best_params_\n",
    "                model=grid.best_estimator_\n",
    "\n",
    "                # st.markdown(\"_\"*200)\n",
    "                result_parameter,mae_parameter=result_evaluator_regressor(model,xtest,ytest)\n",
    "                # ypred_model=model.predict(xtest)\n",
    "                # result_model=r2_score(ytest,ypred_model)\n",
    "                # st.markdown(\"_\"*200)\n",
    "                print(f\"R2 score with best parameter{result_parameter}\")\n",
    "                print(f\"Mean Absoulte Error with best parameter{mae_parameter}\")\n",
    "                # ypred_model=model.predict(xtest)\n",
    "                # result_model=r2_score(ytest,ypred_model)\n",
    "                # st.write(f\"Accuracy with best parameter{result_parameter}\")\n",
    "                # print(f\"R2score of Result Modelwith best estimator is : {result_model}\")\n",
    "        #****************************Result Generation ******************************\n",
    "                result,mae=result_evaluator_regressor(model_selector,xtest,ytest)\n",
    "                # ypred=model_selector.predict(xtest)\n",
    "                # result=r2_score(ytest,ypred)\n",
    "\n",
    "                print(f\"Accuracy without  Best parameter{result}\")\n",
    "                print(f\"Mean Absoulte Error without  best parameter{mae}\")\n",
    "                # print(f\"R2score is without estimator {result}\")\n",
    "                # print(confusion_matrix(ypred,ytest))\n",
    "                # print(classification_report(ypred,ytest))\n",
    "        #*********************************Working on features****************************\n",
    "                xopt=feature_selector.get_feature_names_out()\n",
    "                feature_selection=[]\n",
    "                for x in xopt:\n",
    "                    feature_selection.append(x.split(\"__\")[1])\n",
    "                # st.write(feature_selection)\n",
    "                print(\"The feature Selection are as follow-:\")\n",
    "                print(feature_selection)\n",
    "                print(feature)\n",
    "                print(feature_selection)\n",
    "                Listing.append({\n",
    "                    \"i\":i,\n",
    "                    \"result\":result,\n",
    "                    \"mae\":mae,\n",
    "                    \"result_parameter\":result_parameter,\n",
    "                    \"mae_parameter\":mae_parameter,\n",
    "                #     \"Error_model\":result_model,\n",
    "                    \"columns\":feature_selection,\n",
    "                    \"parameter\":feature\n",
    "                })\n",
    "        print(Listing)\n",
    "\n",
    "        return Listing,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\machine learning\\Project\\Website\\Train_your_model\\Train_your_model\\Rough\\knn.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine%20learning/Project/Website/Train_your_model/Train_your_model/Rough/knn.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49minit\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "model.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str=str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pipeline(steps=[('preprocessor',\\n                 ColumnTransformer(transformers=[('numeric',\\n                                                  Pipeline(steps=[('imputer',\\n                                                                   SimpleImputer(strategy='median')),\\n                                                                  ('scaler',\\n                                                                   StandardScaler())]),\\n                                                  ['Unnamed: 0', 'MSSubClass',\\n                                                   'LotFrontage', 'LotArea',\\n                                                   'OverallQual', 'OverallCond',\\n                                                   'YearBuilt', 'YearRemodAdd',\\n                                                   'MasVnrArea', 'BsmtFinSF1',\\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\\n                                                   'TotalBsmtSF', '1stFlrSF',\\n                                                   '2n...\\n                                                   'HouseStyle', 'RoofStyle',\\n                                                   'RoofMatl', 'Exterior1st',\\n                                                   'Exterior2nd', 'MasVnrType',\\n                                                   'ExterQual', 'ExterCond',\\n                                                   'Foundation', 'BsmtQual',\\n                                                   'BsmtCond', 'BsmtExposure',\\n                                                   'BsmtFinType1',\\n                                                   'BsmtFinType2', 'Heating',\\n                                                   'HeatingQC', 'CentralAir',\\n                                                   'Electrical', ...])])),\\n                ('feature',\\n                 SelectKBest(k=9,\\n                             score_func=<function f_regression at 0x0000029990461B80>)),\\n                ('classifier', GradientBoostingRegressor())])\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "A load persistent id instruction was encountered,\nbut no persistent_load function was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\machine learning\\Project\\Website\\Train_your_model\\Train_your_model\\Rough\\knn.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine%20learning/Project/Website/Train_your_model/Train_your_model/Rough/knn.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mloads(model_str\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mlatin1\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: A load persistent id instruction was encountered,\nbut no persistent_load function was specified."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_data = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist=pd.DataFrame(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"D:\\machine learning\\Project\\Website\\Train_your_model\\Train_model\\userlist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>i</th>\n",
       "      <th>result</th>\n",
       "      <th>mae</th>\n",
       "      <th>result_parameter</th>\n",
       "      <th>mae_parameter</th>\n",
       "      <th>columns</th>\n",
       "      <th>parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682547</td>\n",
       "      <td>31899.574392</td>\n",
       "      <td>0.682387</td>\n",
       "      <td>31918.871357</td>\n",
       "      <td>['OverallQual']</td>\n",
       "      <td>{'classifier__criterion': 'poisson', 'classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  i    result           mae  result_parameter  mae_parameter  \\\n",
       "0           0  1  0.682547  31899.574392          0.682387   31918.871357   \n",
       "\n",
       "           columns                                          parameter  \n",
       "0  ['OverallQual']  {'classifier__criterion': 'poisson', 'classifi...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ove'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"columns\"][0][2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'classifier__criterion': 'poisson', 'classifi...\n",
      "1    {'classifier__criterion': 'absolute_error', 'c...\n",
      "2    {'classifier__criterion': 'absolute_error', 'c...\n",
      "3    {'classifier__criterion': 'absolute_error', 'c...\n",
      "4    {'classifier__criterion': 'absolute_error', 'c...\n",
      "5    {'classifier__criterion': 'poisson', 'classifi...\n",
      "6    {'classifier__criterion': 'poisson', 'classifi...\n",
      "7    {'classifier__criterion': 'absolute_error', 'c...\n",
      "8    {'classifier__criterion': 'absolute_error', 'c...\n",
      "Name: parameter, dtype: object\n"
     ]
    }
   ],
   "source": [
    "column=df[\"parameter\"]\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>criterion': 'absolute_error', 'classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_depth': 10, 'classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_samples_leaf': 1, 'classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_estimators': 50}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "0                               {'classifier\n",
       "1  criterion': 'absolute_error', 'classifier\n",
       "2                max_depth': 10, 'classifier\n",
       "3          min_samples_leaf': 1, 'classifier\n",
       "4                         n_estimators': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(column.str.split(\"__\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
