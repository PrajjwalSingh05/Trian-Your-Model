{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot as plt\n",
    "from  sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import  make_pipeline,Pipeline\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\hp\\Desktop\\file1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "def data_preprocessor(X,y):\n",
    "        \"\"\"Function to Prepocess the data \"\"\"\n",
    "        numeric_transformer = Pipeline(\n",
    "                steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "            )\n",
    "\n",
    "        categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"numeric\", numeric_transformer, X.select_dtypes(np.number).columns.tolist()),\n",
    "                    (\"category\", categorical_transformer,X.select_dtypes(\"object\").columns.tolist()),\n",
    "                ]\n",
    "            )\n",
    "        return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_evaluator_classfication(model,xtest,ytest):\n",
    "         ypred=model.predict(xtest)\n",
    "         cmaxt=confusion_matrix(ytest,ypred)\n",
    "         clrep=classification_report(ytest,ypred)\n",
    "         return clrep,cmaxt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_evaluator_self_classfication(model,xtest,yest):\n",
    "                ypred=model.predict(xtest)\n",
    "                print(f\"THe accuracy is :\",accuracy_score(yest,ypred))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X,y,start,end,parms):\n",
    "        Listing=[]\n",
    "        preprocessor=data_preprocessor(X,y)\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=45)\n",
    "  \n",
    "        for i in range(start,end):\n",
    "        # ****************Feature Seclortot**********************************************\n",
    "                feature_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i))])\n",
    "                feature_selector.fit(xtrain,ytrain)\n",
    "        # ****************Model Selector**********************************************\n",
    "                model_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i)),\n",
    "                    (\"classifier\", RandomForestClassifier())]\n",
    "                )\n",
    "                model_selector.fit(xtrain,ytrain)\n",
    "        # *********************************Hyper Parametet***********************************\n",
    "                grid=GridSearchCV(model_selector,parms,cv=4,n_jobs=-1,verbose=3)\n",
    "                grid.fit(xtrain,ytrain)\n",
    "                feature=grid.best_params_\n",
    "                model=grid.best_estimator_\n",
    "                # ypred_model=model_selector.predict(xtest)\n",
    "                \n",
    "        #****************************Result Generation ******************************\n",
    "                clas_report_parameter,conf_mat_parameter=result_evaluator_classfication(model,xtest,ytest)\n",
    "                \n",
    "                print(\"Confusion Matrix is With Best Perimator:\" , conf_mat_parameter)\n",
    "                # st.write(confusion_matrix(ypred,ytest))\n",
    "                print(\"CLassification Report is With Best Perimator :\",clas_report_parameter)\n",
    "                clas_report,conf_mat_=result_evaluator_classfication(model_selector,xtest,ytest)\n",
    "                print(\"Confusion Matrix is Without Best Perimator:\" , conf_mat_parameter)\n",
    "                # st.write(confusion_matrix(ypred,ytest))\n",
    "                print(\"CLassification Report is  Without Best Perimator:\",clas_report_parameter)\n",
    "                # st.write(classification_report(ypred,ytest))\n",
    "                \n",
    "        #*********************************Working on features****************************\n",
    "                xopt=feature_selector.get_feature_names_out()\n",
    "                feature_selection=[]\n",
    "                for x in xopt:\n",
    "                    feature_selection.append(x.split(\"__\")[1])\n",
    "                print(\"The feature Selection are as follow-:\")\n",
    "                print(feature_selection)\n",
    "                print(\"The Hyper Parameter are as follow -:\")\n",
    "                print(feature)\n",
    "                print(feature_selection)\n",
    "                # st.write(\"************************\")\n",
    "                # st.write(f\"Iteration Number is{i} \")\n",
    "                # print(f\"***********************--{i}******************\")\n",
    "                # print(\"**********new********************\")\n",
    "\n",
    "        # ********************Colecting Data--***********************************************\n",
    "                Listing.append({\n",
    "                    \"i\":i,\n",
    "                    \"Con_mat_para\":conf_mat_parameter,\n",
    "                    \"clas_report_para\":clas_report_parameter,\n",
    "                    # \"Error\":result,\n",
    "                    # \"Error_model\":result_model,\n",
    "                    \"columns\":feature_selection,\n",
    "                    \"parameter\":feature\n",
    "                })\n",
    "                print(\";isting\")\n",
    "                print(\";isting\")\n",
    "                print(\";isting\")\n",
    "                print(Listing)\n",
    "        return Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Confusion Matrix is With Best Perimator: [[  0  33]\n",
      " [  3 114]]\n",
      "CLassification Report is With Best Perimator :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.78      0.97      0.86       117\n",
      "\n",
      "    accuracy                           0.76       150\n",
      "   macro avg       0.39      0.49      0.43       150\n",
      "weighted avg       0.60      0.76      0.67       150\n",
      "\n",
      "Confusion Matrix is Without Best Perimator: [[  0  33]\n",
      " [  3 114]]\n",
      "CLassification Report is  Without Best Perimator:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.78      0.97      0.86       117\n",
      "\n",
      "    accuracy                           0.76       150\n",
      "   macro avg       0.39      0.49      0.43       150\n",
      "weighted avg       0.60      0.76      0.67       150\n",
      "\n",
      "The feature Selection are as follow-:\n",
      "['Recency']\n",
      "The Hyper Parameter are as follow -:\n",
      "{}\n",
      "['Recency']\n",
      ";isting\n",
      ";isting\n",
      ";isting\n",
      "[{'i': 1, 'Con_mat_para': array([[  0,  33],\n",
      "       [  3, 114]], dtype=int64), 'clas_report_para': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00        33\\n           1       0.78      0.97      0.86       117\\n\\n    accuracy                           0.76       150\\n   macro avg       0.39      0.49      0.43       150\\nweighted avg       0.60      0.76      0.67       150\\n', 'columns': ['Recency'], 'parameter': {}}]\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Confusion Matrix is With Best Perimator: [[  6  27]\n",
      " [  4 113]]\n",
      "CLassification Report is With Best Perimator :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.18      0.28        33\n",
      "           1       0.81      0.97      0.88       117\n",
      "\n",
      "    accuracy                           0.79       150\n",
      "   macro avg       0.70      0.57      0.58       150\n",
      "weighted avg       0.76      0.79      0.75       150\n",
      "\n",
      "Confusion Matrix is Without Best Perimator: [[  6  27]\n",
      " [  4 113]]\n",
      "CLassification Report is  Without Best Perimator:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.18      0.28        33\n",
      "           1       0.81      0.97      0.88       117\n",
      "\n",
      "    accuracy                           0.79       150\n",
      "   macro avg       0.70      0.57      0.58       150\n",
      "weighted avg       0.76      0.79      0.75       150\n",
      "\n",
      "The feature Selection are as follow-:\n",
      "['Recency', 'Monetary']\n",
      "The Hyper Parameter are as follow -:\n",
      "{}\n",
      "['Recency', 'Monetary']\n",
      ";isting\n",
      ";isting\n",
      ";isting\n",
      "[{'i': 1, 'Con_mat_para': array([[  0,  33],\n",
      "       [  3, 114]], dtype=int64), 'clas_report_para': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00        33\\n           1       0.78      0.97      0.86       117\\n\\n    accuracy                           0.76       150\\n   macro avg       0.39      0.49      0.43       150\\nweighted avg       0.60      0.76      0.67       150\\n', 'columns': ['Recency'], 'parameter': {}}, {'i': 2, 'Con_mat_para': array([[  6,  27],\n",
      "       [  4, 113]], dtype=int64), 'clas_report_para': '              precision    recall  f1-score   support\\n\\n           0       0.60      0.18      0.28        33\\n           1       0.81      0.97      0.88       117\\n\\n    accuracy                           0.79       150\\n   macro avg       0.70      0.57      0.58       150\\nweighted avg       0.76      0.79      0.75       150\\n', 'columns': ['Recency', 'Monetary'], 'parameter': {}}]\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(columns=[\"Class\"])\n",
    "parms={}\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(df[\"Class\"]) \n",
    "Listing=random_forest_classifier(X,y,1,3,parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifie(X,y,start,end,parms):\n",
    "        Listing=[]\n",
    "        preprocessor=data_preprocessor(X,y)\n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=45)\n",
    "  \n",
    "        for i in range(start,end):\n",
    "        # ****************Feature Seclortot**********************************************\n",
    "                feature_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i))])\n",
    "                feature_selector.fit(xtrain,ytrain)\n",
    "        # ****************Model Selector**********************************************\n",
    "                model_selector = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor),\n",
    "                    (\"feature\", SelectKBest(f_regression,k=i)),\n",
    "                    (\"classifier\", RandomForestClassifier())]\n",
    "                )\n",
    "                model_selector.fit(xtrain,ytrain)\n",
    "        # *********************************Hyper Parametet***********************************\n",
    "                grid=GridSearchCV(model_selector,parms,cv=4,n_jobs=-1,verbose=3)\n",
    "                grid.fit(xtrain,ytrain)\n",
    "                feature=grid.best_params_\n",
    "                model=grid.best_estimator_\n",
    "                # ypred_model=model_selector.predict(xtest)\n",
    "                \n",
    "        #****************************Result Generation ******************************\n",
    "                result_evaluator_self_classfication(model,xtest,ytest)\n",
    "                \n",
    "                # print(\"Confusion Matrix is With Best Perimator:\" , conf_mat_parameter)\n",
    "                # # st.write(confusion_matrix(ypred,ytest))\n",
    "                # print(\"CLassification Report is With Best Perimator :\",clas_report_parameter)\n",
    "                # clas_report,conf_mat_=result_evaluator_classfication(model_selector,xtest,ytest)\n",
    "                # print(\"Confusion Matrix is Without Best Perimator:\" , conf_mat_parameter)\n",
    "                # # st.write(confusion_matrix(ypred,ytest))\n",
    "                # print(\"CLassification Report is  Without Best Perimator:\",clas_report_parameter)\n",
    "                # st.write(classification_report(ypred,ytest))\n",
    "                \n",
    "        #*********************************Working on features****************************\n",
    "                xopt=feature_selector.get_feature_names_out()\n",
    "                feature_selection=[]\n",
    "                for x in xopt:\n",
    "                    feature_selection.append(x.split(\"__\")[1])\n",
    "                print(\"The feature Selection are as follow-:\")\n",
    "                print(feature_selection)\n",
    "                print(\"The Hyper Parameter are as follow -:\")\n",
    "                print(feature)\n",
    "                print(feature_selection)\n",
    "                # st.write(\"************************\")\n",
    "                # st.write(f\"Iteration Number is{i} \")\n",
    "                # print(f\"***********************--{i}******************\")\n",
    "                # print(\"**********new********************\")\n",
    "\n",
    "        # ********************Colecting Data--***********************************************\n",
    "                Listing.append({\n",
    "                #     \"i\":i,\n",
    "                #     \"Con_mat_para\":conf_mat_parameter,\n",
    "                #     \"clas_report_para\":clas_report_parameter,\n",
    "                #     # \"Error\":result,\n",
    "                    # \"Error_model\":result_model,\n",
    "                    \"columns\":feature_selection,\n",
    "                    \"parameter\":feature\n",
    "                })\n",
    "              \n",
    "                # print(Listing)\n",
    "        return Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "THe accuracy is : 0.7666666666666667\n",
      "The feature Selection are as follow-:\n",
      "['Recency']\n",
      "The Hyper Parameter are as follow -:\n",
      "{}\n",
      "['Recency']\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "THe accuracy is : 0.7933333333333333\n",
      "The feature Selection are as follow-:\n",
      "['Recency', 'Monetary']\n",
      "The Hyper Parameter are as follow -:\n",
      "{}\n",
      "['Recency', 'Monetary']\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(columns=[\"Class\"])\n",
    "parms={}\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(df[\"Class\"]) \n",
    "Listing=random_forest_classifie(X,y,1,3,parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_evaluator_self_classfication(model,xtest,yest):\n",
    "                ypred=model.predict(xtest)\n",
    "                print(f\"THe accuracy is :\",accuracy_score(yest,ypred))\n",
    "                print(f\"THe  baclanced accuracy is :\",balanced_accuracy_score(yest,ypred))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"D:/machine learning/Project/Website/Train_your_model/media/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/machine learning/Project/Website/Train_your_model/media/hello\n"
     ]
    }
   ],
   "source": [
    "print(base_url+\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
