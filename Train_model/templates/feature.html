{% extends 'layout/base.html' %}

{% block css %}
<style>
    * {
      box-sizing: border-box;
    }
    body {
      font-family: "Open Sans";

      color: #ecf0f1;
      line-height: 1.618em;
    }
    .tabs {
      position: relative;
      margin: 3rem 0;
      background: #1abc9c;
      height: 34.75rem;
      width:80%
    }
    .tabs::before,
    .tabs::after {
      content: "";
      display: table;
    }
    .tabs::after {
      clear: both;
    }
    .tab {
      float: left;
    }
    .tab-switch {
      display: none;
    }
    .tab-label {
      position: relative;
      display: block;
      line-height: 2.75em;
      height: 3em;
      padding: 0 1.618em;
      background: #1abc9c;
      border-right: 0.125rem solid #16a085;
      color: #fff;
      cursor: pointer;
      top: 0;
      transition: all 0.25s;
    }
    .tab-label:hover {
      top: -0.25rem;
      transition: top 0.25s;
    }
    .tab-content {
      height: 80%;
      position: absolute;
      z-index: 1;
      top: 2.75em;
      left: 0;
      padding: 1.618rem;
      background: #fff;
      color: #2c3e50;
      border-bottom: 0.25rem solid #bdc3c7;
      opacity: 0;
      transition: all 0.35s;
    }
    .tab-switch:checked + .tab-label {
      background: #df9d9d;
      color: #2c3e50;
      border-bottom: 0;
      border-right: 0.125rem solid #fff;
      transition: all 0.35s;
      z-index: 1;
      top: -0.0625rem;
    }
    .tab-switch:checked + label + .tab-content {
      z-index: 2;
      opacity: 1;
      transition: all 0.35s;
    }
</style>
    <!-- CSS -->
{% endblock %}
{% block content %}
<div class="wrapper1">
    <h2 style="color:black">Regression Model</h2>
      <div class="tabs">
        <div class="tab">
          <input type="radio" name="css-tabs-1" id="tab-1" checked class="tab-switch">
          <label for="tab-1" class="tab-label">Desciprion </label>
          <div class="tab-content">This Module Can be Used to train model which have predicution column as numerical </div>
        </div>
        <div class="tab">
          <input type="radio" name="css-tabs-1" id="tab-2" checked class="tab-switch">
          <label for="tab-2" class="tab-label">Model Avialabe </label>
          <div class="tab-content"><ul>
            <li><h5> Random FOrest Regression </h5> <p>Random Forest Regression combines multiple decision trees using a random subset of data and features.</p>  </li>
            <li><h5> KnearestNeighbor <p>K-Nearest Neighbors Regression is a non-parametric model that predicts by averaging the values of the k-nearest data points.</p> </h5>     </li>
            <li><h5> SVM Regressor    <p>upport Vector Regression finds the hyperplane that maximizes the margin between the training data and predicted values, while allowing some error.</p>   </li>
            <li><h5> Gradient Boosting </h5>   <p>Gradient Boosting Regression combines multiple weak learners (usually decision trees) by training them sequentially on the residuals of the previous learners. </p>   </li>
            <li><h5> Decision Tree   <p>Decision Tree Regression builds a tree-like structure to recursively split the data based on the feature that maximizes the reduction in variance. </p></h5> </li>
          </ul> </div>
        </div>
        <div class="tab">
          <input type="radio" name="css-tabs-1" id="tab-3" class="tab-switch">
          <label for="tab-3" class="tab-label">Various Option</label>
          <div class="tab-content"><ul>
            <li><h5>max_depth</h5><p>The maximum depth of the decision tree, controlling the maximum number of levels in the tree.</p></li>
            <li><h5>min_samples_split </h5><p>he minimum number of samples required to split an internal node.</p></li>
            <li><h5>max_featurest </h5><p>he maximum number of features to consider when looking for the best split..</p></li>
            <li><h5>Criteriont </h5><p>The function to measure the quality of a split (either "gini" for the Gini impurity or "entropy" for the information gain)..</p></li>
          </ul>
             </div>
        </div>
       </div>
      </div>
      <div class="wrapper2">
        <h2 style="color:black">Classification Model</h2>
          <div class="tabs">
            <div class="tab">
              <input type="radio" name="css-tabs-2" id="tab-4" checked class="tab-switch">
              <label for="tab-4" class="tab-label">Desription</label>
              <div class="tab-content">This model can be used to train classification model</div>
            </div>
            <div class="tab">
              <input type="radio" name="css-tabs-2" id="tab-5" class="tab-switch">
                <label for="tab-5" class="tab-label">Models</label>
                <div class="tab-content"><ul>
                  <li><h5> Random FOrest Regression </h5> <p>Random Forest Regression combines multiple decision trees using a random subset of data and features.</p>  </li>
                  <li><h5> KnearestNeighbor <p>K-Nearest Neighbors Regression is a non-parametric model that predicts by averaging the values of the k-nearest data points.</p> </h5>     </li>
                  <li><h5> SVM Regressor    <p>upport Vector Regression finds the hyperplane that maximizes the margin between the training data and predicted values, while allowing some error.</p>   </li>
                  <li><h5> Gradient Boosting </h5>   <p>Gradient Boosting Regression combines multiple weak learners (usually decision trees) by training them sequentially on the residuals of the previous learners. </p>   </li>
                  <li><h5> Decision Tree   <p>Decision Tree Regression builds a tree-like structure to recursively split the data based on the feature that maximizes the reduction in variance. </p></h5> </li>
                </ul> </div>
            </div>
            <div class="tab">
              <input type="radio" name="css-tabs-2" id="tab-6" class="tab-switch">
              <label for="tab-6" class="tab-label">Option</label>
              <div class="tab-content"><ul>
                <li><h5>max_depth</h5><p>The maximum depth of the decision tree, controlling the maximum number of levels in the tree.</p></li>
                <li><h5>min_samples_split </h5><p>he minimum number of samples required to split an internal node.</p></li>
                <li><h5>max_featurest </h5><p>he maximum number of features to consider when looking for the best split..</p></li>
                <li><h5>Criteriont </h5><p>The function to measure the quality of a split (either "gini" for the Gini impurity or "entropy" for the information gain)..</p></li>
              </ul>
                 </div>>
            </div>

      </div>
  </div>


  <div class="wrapper3">
    <h2 style="color:black">Download Classification Model</h2>
      <div class="tabs">
        <div class="tab">
          <input type="radio" name="css-tabs-3" id="tab-7" checked class="tab-switch">
          <label for="tab-7" class="tab-label">Desciprion </label>
          <div class="tab-content">This Module Can be Used to train model which have predicution column as numerical </div>
        </div>
        <div class="tab">
          <input type="radio" name="css-tabs-3" id="tab-8" checked class="tab-switch">
          <label for="tab-8" class="tab-label">Model Avialabe </label>
          
          <div class="tab-content"><ul>
            <li><h5> Random FOrest Regression </h5> <p>Random Forest Regression combines multiple decision trees using a random subset of data and features.</p>  </li>
            <li><h5> KnearestNeighbor <p>K-Nearest Neighbors Regression is a non-parametric model that predicts by averaging the values of the k-nearest data points.</p> </h5>     </li>
            <li><h5> SVM Regressor    <p>upport Vector Regression finds the hyperplane that maximizes the margin between the training data and predicted values, while allowing some error.</p>   </li>
            <li><h5> Gradient Boosting </h5>   <p>Gradient Boosting Regression combines multiple weak learners (usually decision trees) by training them sequentially on the residuals of the previous learners. </p>   </li>
            <li><h5> Decision Tree   <p>Decision Tree Regression builds a tree-like structure to recursively split the data based on the feature that maximizes the reduction in variance. </p></h5> </li>
          </ul> </div>
        </div>
        <div class="tab">
          <input type="radio" name="css-tabs-3" id="tab-9" class="tab-switch">
          <label for="tab-9" class="tab-label">Various Option</label>
          <div class="tab-content"><ul>
            <li><h5>max_depth</h5><p>The maximum depth of the decision tree, controlling the maximum number of levels in the tree.</p></li>
            <li><h5>min_samples_split </h5><p>he minimum number of samples required to split an internal node.</p></li>
            <li><h5>max_featurest </h5><p>he maximum number of features to consider when looking for the best split..</p></li>
            <li><h5>Criteriont </h5><p>The function to measure the quality of a split (either "gini" for the Gini impurity or "entropy" for the information gain)..</p></li>
          </ul>
             </div>
        </div>
       </div>
      </div>  


      <div class="wrapper4">
        <h2 style="color:black">Dwonload Regression Model</h2>
          <div class="tabs">
            <div class="tab">
              <input type="radio" name="css-tabs-4" id="tab-10" checked class="tab-switch">
              <label for="tab-10" class="tab-label">Desciprion </label>
              <div class="tab-content">This Module Can be Used to train model which have predicution column as numerical </div>
            </div>
            <div class="tab">
              <input type="radio" name="css-tabs-4" id="tab-11" checked class="tab-switch">
              <label for="tab-11" class="tab-label">Model Avialabe </label>
              
              <div class="tab-content"><ul>
                <li><h5> Random FOrest Regression </h5> <p>Random Forest Regression combines multiple decision trees using a random subset of data and features.</p>  </li>
                <li><h5> KnearestNeighbor <p>K-Nearest Neighbors Regression is a non-parametric model that predicts by averaging the values of the k-nearest data points.</p> </h5>     </li>
                <li><h5> SVM Regressor    <p>upport Vector Regression finds the hyperplane that maximizes the margin between the training data and predicted values, while allowing some error.</p>   </li>
                <li><h5> Gradient Boosting </h5>   <p>Gradient Boosting Regression combines multiple weak learners (usually decision trees) by training them sequentially on the residuals of the previous learners. </p>   </li>
                <li><h5> Decision Tree   <p>Decision Tree Regression builds a tree-like structure to recursively split the data based on the feature that maximizes the reduction in variance. </p></h5> </li>
              </ul> </div>
            </div>
            <div class="tab">
              <input type="radio" name="css-tabs-4" id="tab-12" class="tab-switch">
              <label for="tab-12" class="tab-label">Various Option</label>
              <div class="tab-content"><ul>
                <li><h5>max_depth</h5><p>The maximum depth of the decision tree, controlling the maximum number of levels in the tree.</p></li>
                <li><h5>min_samples_split </h5><p>he minimum number of samples required to split an internal node.</p></li>
                <li><h5>max_featurest </h5><p>he maximum number of features to consider when looking for the best split..</p></li>
                <li><h5>Criteriont </h5><p>The function to measure the quality of a split (either "gini" for the Gini impurity or "entropy" for the information gain)..</p></li>
              </ul>
                 </div>
            </div>
           </div>
          </div>
    <!-- COntent -->
{% endblock %}
{% block js %}
    <!-- Js -->
{% endblock %}